The first of Sunlight Foundation's 32
[Open Data Policy Guidelines](http://sunlightfoundation.com/opendataguidelines/)
is to "Set The Default To Open".

> Most public records systems, including the Freedom of Information Act itself, are systems of reactive disclosure -- meaning that a question has to be asked before an answer given; public information requested, before it is disclosed.
>
> Proactive disclosure is the opposite. Proactive disclosure is the release of public information -- online and in open formats (see Provisions 8 and 9) -- before it is asked for. This is no simple task, but, in a way, it’s what all "open data" is aiming to accomplish. Setting the default to open means that the government and parties acting on its behalf will make public information available proactively and that they’ll put that information within reach of the public (online), with low to no barriers for its reuse and consumption. Open formats may help us maximize on the value we can extract from certain kinds of public data today, but to ensure that data publishing is sustained and, in fact, made easier over time, we need to reset the default for how data is released and disclosed.
>
> Setting the default to open is about living up to the potential of our information, about looking at comprehensive information management, and making determinations that fall in the public interest. It’s about purely practical government improvements, too, and taking steps that not only keep government systems up to date, but ensure that we have the foresight to survive changes in technology that we can’t predict.
>
> Usually, for information to be defined as public, important restrictions have already been applied. Therefore, policy language can be used to outline that "all public data and information must be considered open and accessible." Whether listed as part of a statement of intent (as Austin, Texas does; a concept explored more in Provision 21), as direction to a new oversight authority (Provision 22), or as the underlying aim of new data guidance (Provision 20), openness by default is a critical tool in crafting open data policies that are both ambitious and sustainable.

Software can encourage this practice of making data open by default.

## Display types on Socrata portals
I previously [downloaded](/!/socrata-summary) metadata about all of
the datasets on all of the Socrata portals, and I continue to find
interesting things in these data.

Let's focus on the things that are neither tables nor external links.

```{r not_boring}
not.boring <- subset(socrata.distinct, displayType != '' & displayType != 'table' & displayType != 'href' & displayType != 'blob')
not.boring$displayType <- factor(not.boring$displayType, levels = names(sort(table(not.boring$displayType), decreasing = T)))
ggplot(not.boring) + aes(x = displayType) + geom_bar() + coord_flip()
```

I was somewhat surprised to see forms and calendars in the portals.
I've [previously](/!/open-calendars) written about why I think Socrata calendars are cool,
so now I'm just going to talk about forms.

## Forms
Much of the goal of these portals is to open up existing government data, but
[forms](https://data.wa.gov/Economics/Broadband-Project-Data-Entry/38rz-krmg?) provide a way for citizens to create data.
lets you enter data. A bunch of people have implemented them, but none seems to get accessed much.

```{r form_use_3}
forms <- sqldf('select portal, sum(viewCount) AS "total.view.count", count(*) AS "number.of.forms" FROM socrata where displayType = "form" group by portal')
ggplot(forms) +
  aes(x = number.of.forms, y = total.view.count, label = portal) + geom_text() +
```
I'm gonna remove opendata.socrata.com to make that easier to read.

```{r form_use_4}
forms <- sqldf('select portal, sum(viewCount) AS "total.view.count", count(*) AS "number.of.forms" FROM socrata where displayType = "form" and portal != "opendata.socrata.com" group by portal')
ggplot(forms) +
  aes(x = number.of.forms, y = total.view.count, label = portal) + geom_text() +
  scale_x_continuous('Number of forms in the portal') +
  scale_y_continuous('Total hits across all forms', labels = comma)
```

### Feedback
I hadn't seen [nmfs.socrata.com](https://nmfs.socrata.com) before.
It belongs to the [National Oceanic and Atmospheric Administration Fisheries Service](http://www.nmfs.noaa.gov),
which apparently used [a Socrata form](https://nmfs.socrata.com/Government/2011-Aquaculture-Public-Comments-Form/u5id-8nqp) to power a
[policy comments website](http://www.nmfs.noaa.gov/aquaculture/policy2/).

New York made a form for [feedback on the portal](https://data.ny.gov/dataset/Give-Feedback/fq3e-q75i?).

### Calendar
World Bank Open Finances made a
[form](https://finances.worldbank.org/dataset/Global-Open-Data-Calendar-Entry-Form/qdbh-rfd3?)
that populates an
[open data events calendar](https://finances.worldbank.org/dataset/Global-Open-Data-Calendar/g4sx-dwxc).

## Relevance to software
I see data portal software as sending data from publisher silos to an open, magical website.
How about about prevending data from being siloed in the first place? I previously
[hinted](http://thomaslevine.com/!/socrata-calendars#opening-data-at-their-sources) at this,
but now I have some clear ideas.

The three examples of Socrata forms show us how we can turn user input on a website into
open data automatically. Using a Socrata form to compose a dataset is quite inconvenient,
unreliable, limited, and other bad things, but we can apply this concept with other software.

### Opening user-entered data on your website
If you have a website that stores information in a standard database (like MySQL) and
you separate the private information from the public information, you can quite safely
and easily have it sent to a data portal.

### Storing application data directly in a portal
If you have a simple website, maybe you don't have to run your own database
and write your own web APIs. You could store the data in a data portal, but
if your data have any sort of typical schema, you'll
[find](https://scraperwiki.com/)
[some](http://keen.io)
[other](https://www.parse.com)
[service](http://stormpath.com/)
that does it better.


Unlike data portals, these other services tend not to focus on opening the data

But you
can also do better than 


could use a data portal for this
A bunch
of services


A major part of data portal software and data analysis software is the integrations
with data standard data sources, like relational databases, Google Analytics, &c.

If you have a website that stores information in a standard database and you separate
the private information from the public information, it shouldn't be too hard to send
it to an open data portal. At worst, you'll need to think a little bit about performance
and about denormalizing the data.

It's great if you build a special API too, but the API is likely to have a less standard
format and query language that than a simple database dump.

### Other standard formats
Loads of people use the same 

